{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlejandroAhogado/Proyecto1BI/blob/main/Proyecto_1_Grupo_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW2ms9A6fvKl"
      },
      "source": [
        "# I. Importacion/Instalacion de librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRIQubAcf4Rb",
        "outputId": "b7cac190-ce4e-44fe-9a8e-66987afca0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "#Manejo de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re, string, unicodedata\n",
        "\n",
        "#Visualizaci√≥n de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "#Librer√≠as para manejo de Lenguaje Natural\n",
        "!pip install contractions --quiet\n",
        "import contractions\n",
        "from contractions import contractions_dict\n",
        "import inflect\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "#Entrenamiento del modelo\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.base import BaseEstimator,TransformerMixin\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfg_X8asf8Rh",
        "outputId": "72ede590-1ae6-4d2d-9a4e-01452ac342c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('SuicidiosProyecto.csv',sep=',', encoding='utf-8', error_bad_lines=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZuBN3AQf4kj"
      },
      "source": [
        "# II. Exploramiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be8fzsYwwthB"
      },
      "source": [
        "Se hace una exploracion inicial de los datos para ver en que formato estan presentados y que tipo de pre-proesamiento hay que hacer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Mw9r4pl1wdqu",
        "outputId": "1ff74006-354d-4ea5-f5d4-5595f1cdf128"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text        class\n",
              "0      173271  i want to destroy myselffor once everything wa...      suicide\n",
              "1      336321  I kinda got behind schedule with learning for ...  non-suicide\n",
              "2      256637  I'm just not sure anymoreFirst and foremost: I...      suicide\n",
              "3      303772  please give me a reason to liveThats too much ...      suicide\n",
              "4      293747  27f struggling to find meaning moving forwardI...      suicide\n",
              "5      205651  Let‚Äôs get this bread üòé Anyone know any good ba...  non-suicide\n",
              "6       97174  Day 126 of posting random \"fun\" facts everyday...  non-suicide\n",
              "7      195945  Little brother is self mutilating. Please help...      suicide\n",
              "8      305273  Why do women always go in groups to their wash...  non-suicide\n",
              "9       69929  Did you guys know that there's no school for g...  non-suicide"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7aeffaf-f4e6-401d-9f2a-d5b43fe951de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>173271</td>\n",
              "      <td>i want to destroy myselffor once everything wa...</td>\n",
              "      <td>suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>336321</td>\n",
              "      <td>I kinda got behind schedule with learning for ...</td>\n",
              "      <td>non-suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>256637</td>\n",
              "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
              "      <td>suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303772</td>\n",
              "      <td>please give me a reason to liveThats too much ...</td>\n",
              "      <td>suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>293747</td>\n",
              "      <td>27f struggling to find meaning moving forwardI...</td>\n",
              "      <td>suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>205651</td>\n",
              "      <td>Let‚Äôs get this bread üòé Anyone know any good ba...</td>\n",
              "      <td>non-suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>97174</td>\n",
              "      <td>Day 126 of posting random \"fun\" facts everyday...</td>\n",
              "      <td>non-suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>195945</td>\n",
              "      <td>Little brother is self mutilating. Please help...</td>\n",
              "      <td>suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>305273</td>\n",
              "      <td>Why do women always go in groups to their wash...</td>\n",
              "      <td>non-suicide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>69929</td>\n",
              "      <td>Did you guys know that there's no school for g...</td>\n",
              "      <td>non-suicide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7aeffaf-f4e6-401d-9f2a-d5b43fe951de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7aeffaf-f4e6-401d-9f2a-d5b43fe951de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7aeffaf-f4e6-401d-9f2a-d5b43fe951de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytl5fN_Kf8kA"
      },
      "source": [
        "# III. Preprocesamiento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AC6ysyhxO_L"
      },
      "source": [
        "## 3.1 Transformacion columna objetivo\n",
        "\n",
        "Inicialmente se cambia la columna objetivo a un valor binario 0/1 que corresponde a las categorias de non-suicide/suicide respectivamente. Tambien se elimina la columna \"unnamed:0\" pues esta corresponde a un identificador unico que no es relevante para la tarea propuesta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "vV-EgDnGyZ7S",
        "outputId": "bc0656c9-94b4-4b66-90d2-767227b3228d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  class\n",
              "0       i want to destroy myselffor once everything wa...      1\n",
              "1       I kinda got behind schedule with learning for ...      0\n",
              "2       I'm just not sure anymoreFirst and foremost: I...      1\n",
              "3       please give me a reason to liveThats too much ...      1\n",
              "4       27f struggling to find meaning moving forwardI...      1\n",
              "...                                                   ...    ...\n",
              "195695  Drop some cool new cereal ideas Like what woul...      0\n",
              "195696  Unpopular opinion but cats deserve love and re...      0\n",
              "195697                         Hey guys :) How yall doin?      0\n",
              "195698  uhm I covered my dog in a blanket because the ...      0\n",
              "195699  ____god. how do i do it. how do i end my life....      1\n",
              "\n",
              "[195700 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f2ce594-e728-4828-98d7-2ccdf9487ecd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i want to destroy myselffor once everything wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I kinda got behind schedule with learning for ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>please give me a reason to liveThats too much ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27f struggling to find meaning moving forwardI...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195695</th>\n",
              "      <td>Drop some cool new cereal ideas Like what woul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195696</th>\n",
              "      <td>Unpopular opinion but cats deserve love and re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195697</th>\n",
              "      <td>Hey guys :) How yall doin?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195698</th>\n",
              "      <td>uhm I covered my dog in a blanket because the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195699</th>\n",
              "      <td>____god. how do i do it. how do i end my life....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195700 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f2ce594-e728-4828-98d7-2ccdf9487ecd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f2ce594-e728-4828-98d7-2ccdf9487ecd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f2ce594-e728-4828-98d7-2ccdf9487ecd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df=data.copy()\n",
        "df=df.drop(df.columns[0], axis=1)\n",
        "df['class'].replace(('suicide'), ('1'), inplace=True)\n",
        "df['class'].replace(('non-suicide'), ('0'), inplace=True)\n",
        "df['class'] = pd.to_numeric(df['class'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BogIUoM50nHV"
      },
      "source": [
        "Ademas se valida el contenido de la columna 'class' para verificar que no haya ninguna inconsistencia con los labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f2WZwbC0yhN",
        "outputId": "30f5f6b1-ef4b-4c71-9d2f-edc068c531de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    110165\n",
              "1     85535\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14b-_pQY3HFn"
      },
      "source": [
        "Tambien se valida la validez y completitud de los datos verificando que no hallan nulos o duplicados y eliminando las filas correspondientes en caso que se encuentren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eijKiNkV3GwJ",
        "outputId": "3d92a5f1-7fdb-4d5a-b0c3-fa7f5b4c02f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    195700\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.duplicated().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC4xSLHJ3V7-",
        "outputId": "600195b6-3ca6-44d9-b127-d275f7d3a8af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "text          0\n",
              "class         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roUVrxRd1-Rv"
      },
      "source": [
        "Por ultimo se verifica que las columnas tengan el tipo de dato apropiado para su procesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZiuTQyx2FwO",
        "outputId": "ae0a11be-1c19-4291-eb02-92c056e9b5c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     object\n",
              "class     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwxUDQ0wxCZz"
      },
      "source": [
        "## 3.2 Preparacion de datos\n",
        "Todos los pasos contenidos en esta seccion corresponden a la limpieza y pre proceamiento del texto en la columna 'text' para poder dejarlo en un formato apto para su posterior evaluacion con modelos de PLN. Inicialmente se separan los datos en texto y labels para poder realizar ls tareas de limpieza solo sobre los datos de texto que lo requieren\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, data_small = train_test_split(df, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "4f9iHmR0aMtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2zAmCplEo-N",
        "outputId": "d7505d7c-258a-4368-aad5-937e1b307616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tama√±o del conjunto de entrenamiento: 31312\n",
            "Tama√±o del conjunto de evaluaci√≥n: 7828\n"
          ]
        }
      ],
      "source": [
        "train, test = train_test_split(data_small, test_size=0.2, random_state=42)\n",
        "X_train, y_train = train['text'], train['class']\n",
        "X_test, y_test = test['text'], test['class']\n",
        "print(\"Tama√±o del conjunto de entrenamiento: \"+str(X_train.size))\n",
        "print(\"Tama√±o del conjunto de evaluaci√≥n: \"+str(X_test.size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cYv9bRkhXg9"
      },
      "source": [
        "### 3.2.1 Eliminacion contracciones\n",
        "\n",
        "Eliminar contracciones permite reducir el tama√±o del diccionario y evita que se tomen como palabras distintas casos como, por ejemplo, won't = will not. I'm = I am"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZv4IwaigCPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0deb1cd0-a664-4389-8924-0e02aa666b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    I really hate my life.I am 13 years old and I ...\n",
              "60450     I Am ending it tonightim leaving so many frien...\n",
              "159181    Yo anyone down to chat? I am 14M, very emo, an...\n",
              "63934     Someone knocked Is not it fun that one of my p...\n",
              "90090     I do not know what to do and I am scared that ...\n",
              "                                ...                        \n",
              "161943                   i am uselesshaving a panic attack.\n",
              "188694    I feel like ending it would feel better than s...\n",
              "20015     Sometimes I just feel like I cannot do this an...\n",
              "141904    i have lost the will to live anymore,i am goin...\n",
              "127158    The release of the new Netflix film is the dra...\n",
              "Name: text, Length: 31312, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_clean= X_train.apply(contractions.fix) #Aplica la correcci√≥n de las contracciones\n",
        "X_clean_test= X_test.apply(contractions.fix) #Aplica la correcci√≥n de las contracciones\n",
        "X_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_EcCdYahZKF"
      },
      "source": [
        "### 3.2.2 Minusculas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvjh1WcI_Ycv"
      },
      "outputs": [],
      "source": [
        "def to_lowercase(phrase):\n",
        "    new_phrase = []\n",
        "    for word in phrase:\n",
        "        new_word = word.lower()\n",
        "        new_phrase.append(new_word)\n",
        "    return \"\".join(new_phrase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUr6WmbB_cUd",
        "outputId": "a242167c-0565-4569-f6f7-0d20968312fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    i really hate my life.i am 13 years old and i ...\n",
              "60450     i am ending it tonightim leaving so many frien...\n",
              "159181    yo anyone down to chat? i am 14m, very emo, an...\n",
              "63934     someone knocked is not it fun that one of my p...\n",
              "90090     i do not know what to do and i am scared that ...\n",
              "                                ...                        \n",
              "161943                   i am uselesshaving a panic attack.\n",
              "188694    i feel like ending it would feel better than s...\n",
              "20015     sometimes i just feel like i cannot do this an...\n",
              "141904    i have lost the will to live anymore,i am goin...\n",
              "127158    the release of the new netflix film is the dra...\n",
              "Name: text, Length: 31312, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_clean=X_clean.apply(to_lowercase)\n",
        "X_clean_test=X_clean_test.apply(to_lowercase)\n",
        "X_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pi8JKeKhadj"
      },
      "source": [
        "### 3.2.3 puntuacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-8Q9r4l_8g4"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(phrase):\n",
        "    return phrase.translate(str.maketrans('','',string.punctuation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4rl122J_9aL",
        "outputId": "e45451fc-6cc6-4554-bd6e-0be6d367e569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    i really hate my lifei am 13 years old and i r...\n",
              "60450     i am ending it tonightim leaving so many frien...\n",
              "159181    yo anyone down to chat i am 14m very emo and i...\n",
              "63934     someone knocked is not it fun that one of my p...\n",
              "90090     i do not know what to do and i am scared that ...\n",
              "                                ...                        \n",
              "161943                    i am uselesshaving a panic attack\n",
              "188694    i feel like ending it would feel better than s...\n",
              "20015     sometimes i just feel like i cannot do this an...\n",
              "141904    i have lost the will to live anymorei am going...\n",
              "127158    the release of the new netflix film is the dra...\n",
              "Name: text, Length: 31312, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_clean=X_clean.apply(remove_punctuation)\n",
        "X_clean_test=X_clean_test.apply(remove_punctuation)\n",
        "X_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXVSI0S3iCbQ"
      },
      "source": [
        "### 3.2.4 Remover stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUNBMHs4BBKJ"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(phrase, stopwords=stopwords.words('english')):\n",
        "    words=phrase.split(\" \")\n",
        "    new_phrase = []\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            new_phrase.append(word)\n",
        "            new_phrase.append(\" \")\n",
        "    return \"\".join(new_phrase)[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ApJmvrBEYW",
        "outputId": "afb8a669-9155-41d1-b75b-bf3c38df5633"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    really hate lifei 13 years old really hate lif...\n",
              "60450     ending tonightim leaving many friends pets gir...\n",
              "159181    yo anyone chat 14m emo spotify addict longest ...\n",
              "63934     someone knocked fun one parents knocked door e...\n",
              "90090     know scared screw something bestie f really cl...\n",
              "                                ...                        \n",
              "161943                           uselesshaving panic attack\n",
              "188694    feel like ending would feel better suffering d...\n",
              "20015     sometimes feel like cannot anymoremaybe partia...\n",
              "141904    lost live anymorei going kill 2 hour 15 mintue...\n",
              "127158    release new netflix film drama september liter...\n",
              "Name: text, Length: 31312, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_clean=X_clean.apply(remove_stopwords)\n",
        "X_clean_test=X_clean_test.apply(remove_stopwords)\n",
        "X_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBkhp00OiHKb"
      },
      "source": [
        "## 3.3  Tokenizacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVMtXTkgB033",
        "outputId": "b563c9cd-8807-4891-9755-b4eb065fd855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    [really, hate, lifei, 13, years, old, really, ...\n",
              "60450     [ending, tonightim, leaving, many, friends, pe...\n",
              "159181    [yo, anyone, chat, 14m, emo, spotify, addict, ...\n",
              "63934     [someone, knocked, fun, one, parents, knocked,...\n",
              "90090     [know, scared, screw, something, bestie, f, re...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_clean = X_clean.apply(word_tokenize)\n",
        "X_clean_test = X_clean_test.apply(word_tokenize)\n",
        "X_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1XjGs2aiJvR"
      },
      "source": [
        "## 3.4 Lematizacion/Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwkiszabh07g"
      },
      "outputs": [],
      "source": [
        "# Funciones tomadas de https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def stem_and_lemmatize(words):\n",
        "    words = lemmatize_verbs(words)\n",
        "    words = stem_words(words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5jgjJDPCUVW",
        "outputId": "6492a405-b2f2-456c-dde5-91663e6e0607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 46.1 s, sys: 461 ms, total: 46.5 s\n",
            "Wall time: 46.6 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783    [real, hat, life, 13, year, old, real, hat, li...\n",
              "60450     [end, tonightim, leav, many, friend, pet, girl...\n",
              "159181    [yo, anyon, chat, 14m, emo, spot, addict, long...\n",
              "63934     [someon, knock, fun, on, par, knock, door, eve...\n",
              "90090     [know, scar, screw, someth, besty, f, real, cl...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "%%time\n",
        "X_clean = X_clean.apply(stem_and_lemmatize) \n",
        "X_clean_test = X_clean_test.apply(stem_and_lemmatize)\n",
        "X_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITaaAeQwgBYF"
      },
      "source": [
        "# IV. Implementacion de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb_l23G9JJeh"
      },
      "source": [
        "## Representacion vectorial de datos\n",
        "\n",
        "Dado que es necesario realizar una representacion vectorial del texto para su posterior procesamiento se seleccionan 3 tipos de representacion diferentes, para cada modelo se van a utilizar las 3 representaciones vectoriales para poder seleccionar el mejor resultado posible \n",
        "\n",
        "\n",
        "*   Matriz de Frecuencia\n",
        "*   Representacion termino documento (TFIDF)\n",
        "*   Matriz binaria\n",
        "\n",
        "Inicialmente se combinan todos los tokens que componen cada sentencia en un string para poder crear representaciones matriciales "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgZaUcgrN2CM",
        "outputId": "237de058-7b4b-4dd8-f146-4c7245a9d269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170783      real hat life 13 year old real hat lif want die\n",
              "60450     end tonightim leav many friend pet girlfriend ...\n",
              "159181    yo anyon chat 14m emo spot addict longest play...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_clean = X_clean.apply(lambda x: ' '.join(map(str, x)))\n",
        "X_clean_test = X_clean_test.apply(lambda x: ' '.join(map(str, x)))\n",
        "X_clean.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmdd1DYJxbF"
      },
      "source": [
        "### Matriz frecuencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygvQvLT4J1Hs",
        "outputId": "dba74eb0-8573-48bf-ed0a-5ef3bfd9fe61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31312, 40792)\n"
          ]
        }
      ],
      "source": [
        "# Tambi√©n, se puede realizar el conteo de las palabras presentes.\n",
        "count = CountVectorizer()\n",
        "X_count = count.fit_transform(X_clean)\n",
        "print(X_count.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_count_test=count.transform(X_clean_test)\n",
        "print(X_count_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFjjVGAWTUR-",
        "outputId": "98ab6a7b-b09a-458c-9488-36106d97c876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7828, 40792)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uucN75lXJ1tC"
      },
      "source": [
        "### tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6exm6QMyJ2Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a578584-51ba-4eff-9d99-068eb82fb6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31312, 40792)\n"
          ]
        }
      ],
      "source": [
        "#Se puede realizar la transformaci√≥n Term-frecuency times inverse Document-frecuency.\n",
        "tf_idf = TfidfVectorizer()\n",
        "X_tf_idf = tf_idf.fit_transform(X_clean)\n",
        "print(X_tf_idf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_TfIdf_test=tf_idf.transform(X_clean_test)\n",
        "print(X_TfIdf_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oags5RR2TmFj",
        "outputId": "b1cf743c-8a26-4dd7-ebd5-09fbd63e93fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7828, 40792)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTK8BEpcJ3DH"
      },
      "source": [
        "### Binaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_5EKaiHJ3gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca137df-53ee-446d-c3c4-17284b5741e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31312, 40792)\n"
          ]
        }
      ],
      "source": [
        "# Se transforma el texto con una transformaci√≥n binaria 1 a 1.\n",
        "binary = CountVectorizer(binary=True, lowercase = False)\n",
        "X_binary = binary.fit_transform(X_clean)\n",
        "print(X_binary.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_binary_test=binary.transform(X_clean_test)\n",
        "print(X_binary_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8s90EAnT8sY",
        "outputId": "8832ec9e-bb09-414e-d888-af87724aad4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7828, 40792)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datasets={\"binary\":X_binary,\n",
        "                \"count\":X_count,\n",
        "                \"tfidf\":X_tf_idf}\n",
        "test_datasets={\"binary\":X_binary_test,\n",
        "                \"count\":X_count_test,\n",
        "                \"tfidf\":X_TfIdf_test}"
      ],
      "metadata": {
        "id": "CieN6GwOUESN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues,size=(10,10)):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=size)\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "metadata": {
        "id": "uR7IShX1cmzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_binary.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAFMmh5dOcG",
        "outputId": "02e4163d-29f7-48d7-ed5e-bc06a9029a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31312, 40792)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqLAdE_OdZuP",
        "outputId": "81f5eeae-fd34-4017-be4c-fb36a2ad9cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31312,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y04Aol93gG0j"
      },
      "source": [
        "## 4.1 Algoritmo 1: Arbol de decision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrVXC9cAgGZV"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "        ('classifier', DecisionTreeClassifier(random_state=0))          \n",
        "    ]\n",
        "\n",
        "parameters = {\n",
        "              'classifier__criterion':['gini','entropy'],\n",
        "              'classifier__max_depth':[30,40,50,60,70],\n",
        "            }\n",
        "\n",
        "pipe_tree = Pipeline(estimators)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "best_trees={}\n",
        "for key in train_datasets:\n",
        "  grid_search_tree = GridSearchCV(pipe_tree, parameters, scoring='f1', cv=3, verbose=3)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    grid_search_tree.fit(train_datasets[key],y_train)\n",
        "    best_trees[key]=grid_search_tree.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH25_YvzUOom",
        "outputId": "32919ece-9e2c-42b9-e139-77f4f27c69ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.816 total time=   5.5s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.829 total time=   7.3s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.829 total time=   5.4s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.811 total time=   6.3s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.827 total time=   6.1s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.824 total time=   6.2s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.810 total time=   6.6s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.823 total time=   8.5s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.826 total time=   6.7s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.809 total time=   7.1s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.823 total time=   7.1s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.824 total time=   7.6s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.811 total time=   8.1s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.821 total time=   8.0s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.823 total time=   7.9s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.806 total time=   5.6s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.816 total time=   5.7s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.817 total time=   5.6s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.806 total time=   6.1s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.818 total time=   6.2s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.814 total time=   6.3s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.805 total time=   6.5s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.818 total time=   6.8s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.815 total time=   6.2s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.809 total time=   6.3s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.812 total time=   6.4s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.810 total time=  11.4s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.806 total time=   7.0s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.812 total time=   8.5s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.815 total time=   6.6s\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.813 total time=   5.6s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.826 total time=   5.5s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.828 total time=   5.6s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.816 total time=   6.3s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.819 total time=   6.3s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.827 total time=   6.3s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.811 total time=   6.8s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.817 total time=   6.7s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.825 total time=   6.7s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.811 total time=   7.1s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.817 total time=   7.0s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.828 total time=   7.2s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.810 total time=   7.7s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.816 total time=   7.5s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.824 total time=   7.5s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.807 total time=   5.3s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.820 total time=   5.4s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.816 total time=   5.2s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.806 total time=   6.6s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.816 total time=   7.7s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.813 total time=   6.0s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.803 total time=   6.4s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.817 total time=   6.5s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.814 total time=   6.4s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.804 total time=   6.5s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.813 total time=   6.6s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.811 total time=   6.6s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.808 total time=   6.7s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.811 total time=   6.7s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.809 total time=   6.8s\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.820 total time=   6.6s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.827 total time=   6.8s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=30;, score=0.822 total time=   6.7s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.819 total time=   7.5s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.830 total time=   7.7s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=40;, score=0.821 total time=   7.6s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.822 total time=   8.1s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.824 total time=   8.4s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=50;, score=0.823 total time=  10.1s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.821 total time=   8.3s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.827 total time=   8.5s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=60;, score=0.819 total time=   8.6s\n",
            "[CV 1/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.818 total time=   8.4s\n",
            "[CV 2/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.822 total time=   8.8s\n",
            "[CV 3/3] END classifier__criterion=gini, classifier__max_depth=70;, score=0.814 total time=   8.9s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.812 total time=   7.4s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.812 total time=   6.9s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=30;, score=0.817 total time=   7.0s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.805 total time=   8.2s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.812 total time=   8.4s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=40;, score=0.817 total time=   8.7s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.803 total time=   9.2s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.804 total time=   9.0s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=50;, score=0.809 total time=   9.0s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.805 total time=   9.7s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.805 total time=  11.2s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=60;, score=0.811 total time=   9.7s\n",
            "[CV 1/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.801 total time=   9.8s\n",
            "[CV 2/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.802 total time=   9.1s\n",
            "[CV 3/3] END classifier__criterion=entropy, classifier__max_depth=70;, score=0.809 total time=   9.3s\n",
            "CPU times: user 11min 23s, sys: 806 ms, total: 11min 24s\n",
            "Wall time: 11min 23s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO5o2hOSdqTQ",
        "outputId": "ed75545a-5004-45d7-c38b-cc0624ab6b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7828,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=best_trees[key]['classifier']\n",
        "y_pred=model.predict(test_datasets[key])"
      ],
      "metadata": {
        "id": "w1Er-AJDjJDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UALoONVvdssK",
        "outputId": "1faa64b3-4f97-48bd-c2ae-6eb4746d3d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7828,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_results={}\n",
        "for key in best_trees:\n",
        "  model=best_trees[key]['classifier']\n",
        "  y_pred=model.predict(test_datasets[key])\n",
        "  acc=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "  prec=precision_score(y_true=y_test, y_pred=y_pred)\n",
        "  recall=recall_score(y_true=y_test, y_pred=y_pred)\n",
        "  f1=f1_score(y_true=y_test, y_pred=y_pred)\n",
        "  tree_results[key]=[best_trees[key]['classifier'], acc, prec, recall, f1]"
      ],
      "metadata": {
        "id": "bzdrQVjeURo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results=pd.DataFrame.from_dict(tree_results, orient='index')\n",
        "mapping = {df_results.columns[1]: 'Accuracy', df_results.columns[2]: 'Precision', df_results.columns[3]: 'Recall', df_results.columns[4]: 'F1', df_results.columns[0]: 'Tree type'}\n",
        "df_results = df_results.rename(columns=mapping)\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "NTID1L0NUVpF",
        "outputId": "47d88987-7a26-4e25-cc0b-221ea3cd793d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Tree type  Accuracy  \\\n",
              "binary  DecisionTreeClassifier(max_depth=30, random_st...  0.856541   \n",
              "count   DecisionTreeClassifier(max_depth=30, random_st...  0.858201   \n",
              "tfidf   DecisionTreeClassifier(max_depth=30, random_st...  0.855391   \n",
              "\n",
              "        Precision    Recall        F1  \n",
              "binary   0.859660  0.801408  0.829513  \n",
              "count    0.864111  0.800235  0.830947  \n",
              "tfidf    0.857233  0.801408  0.828381  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98afc874-2f64-42ce-b481-c44acaf55ba5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tree type</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>binary</th>\n",
              "      <td>DecisionTreeClassifier(max_depth=30, random_st...</td>\n",
              "      <td>0.856541</td>\n",
              "      <td>0.859660</td>\n",
              "      <td>0.801408</td>\n",
              "      <td>0.829513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>DecisionTreeClassifier(max_depth=30, random_st...</td>\n",
              "      <td>0.858201</td>\n",
              "      <td>0.864111</td>\n",
              "      <td>0.800235</td>\n",
              "      <td>0.830947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tfidf</th>\n",
              "      <td>DecisionTreeClassifier(max_depth=30, random_st...</td>\n",
              "      <td>0.855391</td>\n",
              "      <td>0.857233</td>\n",
              "      <td>0.801408</td>\n",
              "      <td>0.828381</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98afc874-2f64-42ce-b481-c44acaf55ba5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98afc874-2f64-42ce-b481-c44acaf55ba5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98afc874-2f64-42ce-b481-c44acaf55ba5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_aRnUIQn-wP",
        "outputId": "fbd0292a-e473-40fe-9469-c954538e949e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary': [DecisionTreeClassifier(max_depth=30, random_state=0),\n",
              "  0.8565406234031682,\n",
              "  0.8596601636249214,\n",
              "  0.801408037547668,\n",
              "  0.8295126764839836],\n",
              " 'count': [DecisionTreeClassifier(max_depth=30, random_state=0),\n",
              "  0.8582013285641288,\n",
              "  0.8641114982578397,\n",
              "  0.8002346729246114,\n",
              "  0.8309473042948524],\n",
              " 'tfidf': [DecisionTreeClassifier(max_depth=30, random_state=0),\n",
              "  0.85539090444558,\n",
              "  0.8572325070599309,\n",
              "  0.801408037547668,\n",
              "  0.8283808368708308]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyXSaTDngKNY"
      },
      "source": [
        "## 4.2 Algoritmo 2: KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKaepC86gLY7"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "        ('classifier', KNeighborsClassifier())          \n",
        "    ]\n",
        "\n",
        "parameters = {\n",
        "              'classifier__weights':['uniform','distance'],\n",
        "              'classifier__n_neighbors':[5,6,7,8,9,10,11,12],\n",
        "              'classifier__p':[1,2],\n",
        "            }\n",
        "\n",
        "pipe_knn = Pipeline(estimators)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "best_knn={}\n",
        "for key in train_datasets:\n",
        "  grid_search_knn = GridSearchCV(pipe_knn, parameters, scoring='f1', cv=3, verbose=3)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    grid_search_knn.fit(train_datasets[key],y_train)\n",
        "    best_knn[key]=grid_search_knn.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lao4xo9joMVq",
        "outputId": "17b5cf78-2383-4df5-f6d4-9dc086e35372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.620 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.644 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.648 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.620 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.645 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.648 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.620 total time=  13.6s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.644 total time=   9.2s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.648 total time=  10.4s\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.620 total time=  10.9s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.645 total time=   9.0s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.648 total time=  10.0s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.532 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.558 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.571 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.614 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.641 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.641 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.532 total time=  12.3s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.558 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.571 total time=  10.9s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.614 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.641 total time=   9.5s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.641 total time=  10.7s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.605 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.630 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.639 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.605 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.631 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.639 total time= 1.2min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.605 total time=  15.3s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.630 total time=  13.5s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.639 total time=  19.0s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.605 total time=  14.1s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.630 total time=  11.3s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.639 total time=  12.1s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.537 total time= 1.2min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.558 total time= 1.2min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.571 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.605 total time= 1.2min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.636 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.636 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.537 total time=  12.1s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.558 total time=  10.1s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.571 total time=  11.3s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.606 total time=  11.9s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.635 total time=  10.0s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.636 total time=  10.8s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.593 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.616 total time= 1.2min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.629 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.594 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.616 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.629 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.593 total time=  13.4s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.616 total time=   9.8s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.629 total time=  10.7s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.593 total time=  11.4s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.616 total time=  11.7s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.629 total time=  10.8s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.524 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.555 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.568 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.596 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.622 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.631 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.524 total time=  12.8s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.555 total time=   9.7s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.568 total time=  10.6s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.596 total time=  12.6s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.621 total time=   9.3s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.631 total time=  10.4s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.571 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.606 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.615 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.571 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.607 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.616 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.571 total time=  11.8s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.606 total time=  10.0s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.615 total time=  11.0s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.571 total time=  11.4s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.606 total time=   9.8s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.616 total time=  10.6s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.510 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.548 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.561 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.578 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.619 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.624 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.510 total time=  11.6s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.548 total time=   9.8s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.561 total time=  10.8s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.577 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.618 total time=   9.5s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.623 total time=  11.1s\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.624 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.640 total time= 1.2min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.655 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.625 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.641 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.656 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.710 total time=  12.5s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.719 total time=  10.5s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.715 total time=  11.2s\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.710 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.719 total time=  10.2s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.716 total time=  10.7s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.527 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.561 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.578 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.615 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.642 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.651 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.660 total time=  12.2s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.670 total time=   9.9s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.669 total time=  10.6s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.713 total time=  10.7s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.714 total time=   9.7s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.716 total time=  11.7s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.604 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.632 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.646 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.604 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.633 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.647 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.711 total time=  11.0s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.713 total time=   9.9s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.710 total time=  10.5s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.711 total time=  10.7s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.713 total time=   9.6s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.711 total time=  10.2s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.526 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.566 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.584 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.600 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.636 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.650 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.663 total time=  11.4s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.669 total time=  11.3s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.673 total time=  10.6s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.708 total time=  10.8s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.713 total time=   9.7s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.715 total time=  10.3s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.585 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.619 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.635 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.586 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.620 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.636 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.702 total time=  12.2s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.711 total time=  10.7s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.710 total time=  11.3s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.703 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.711 total time=  10.2s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.710 total time=  10.9s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.518 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.560 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.583 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.591 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.625 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.641 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.666 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.673 total time=  10.4s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.675 total time=  11.1s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.706 total time=  11.0s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.712 total time=   9.9s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.714 total time=  10.7s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.567 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.612 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.626 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.567 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.613 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.626 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.698 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.704 total time=  10.4s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.704 total time=  12.9s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.699 total time=  11.2s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.704 total time=  10.0s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.704 total time=  10.8s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.512 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.557 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.575 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.572 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.618 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.634 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.668 total time=  11.3s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.671 total time=  10.2s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.675 total time=  10.7s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.702 total time=  10.9s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.708 total time=   9.8s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.707 total time=  10.6s\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.001 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=uniform;, score=0.001 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.004 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.004 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=1, classifier__weights=distance;, score=0.004 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.012 total time=  11.7s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.012 total time=  11.5s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=uniform;, score=0.010 total time=  11.3s\n",
            "[CV 1/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.013 total time=  10.2s\n",
            "[CV 2/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.013 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=5, classifier__p=2, classifier__weights=distance;, score=0.011 total time=  11.3s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.001 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.002 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.004 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=1, classifier__weights=distance;, score=0.003 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.006 total time=  10.8s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.007 total time=  11.9s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=uniform;, score=0.007 total time=  11.8s\n",
            "[CV 1/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.012 total time=  10.5s\n",
            "[CV 2/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.013 total time=  11.5s\n",
            "[CV 3/3] END classifier__n_neighbors=6, classifier__p=2, classifier__weights=distance;, score=0.011 total time=  11.2s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.001 total time= 1.1min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.003 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=1, classifier__weights=distance;, score=0.003 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.007 total time=  11.0s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.007 total time=  11.6s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=uniform;, score=0.007 total time=  11.4s\n",
            "[CV 1/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.008 total time=  10.2s\n",
            "[CV 2/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.008 total time=  11.0s\n",
            "[CV 3/3] END classifier__n_neighbors=7, classifier__p=2, classifier__weights=distance;, score=0.008 total time=  11.0s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.002 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=1, classifier__weights=distance;, score=0.003 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.004 total time=  10.6s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.006 total time=  11.3s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=uniform;, score=0.006 total time=  11.1s\n",
            "[CV 1/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.007 total time=  10.4s\n",
            "[CV 2/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.008 total time=  12.0s\n",
            "[CV 3/3] END classifier__n_neighbors=8, classifier__p=2, classifier__weights=distance;, score=0.014 total time=  10.8s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=uniform;, score=0.034 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.002 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=1, classifier__weights=distance;, score=0.031 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.005 total time=  10.3s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.006 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=uniform;, score=0.593 total time=  11.1s\n",
            "[CV 1/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.005 total time=  10.0s\n",
            "[CV 2/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.006 total time=  10.9s\n",
            "[CV 3/3] END classifier__n_neighbors=9, classifier__p=2, classifier__weights=distance;, score=0.563 total time=  10.9s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=uniform;, score=0.018 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.002 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=1, classifier__weights=distance;, score=0.020 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.004 total time=  10.3s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.003 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=uniform;, score=0.558 total time=  11.4s\n",
            "[CV 1/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.005 total time=  11.8s\n",
            "[CV 2/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.006 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=10, classifier__p=2, classifier__weights=distance;, score=0.561 total time=  11.2s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=uniform;, score=0.053 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=1, classifier__weights=distance;, score=0.050 total time= 1.1min\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.004 total time=  10.8s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.004 total time=  11.6s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=uniform;, score=0.716 total time=  11.5s\n",
            "[CV 1/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.004 total time=  10.4s\n",
            "[CV 2/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.004 total time=  11.4s\n",
            "[CV 3/3] END classifier__n_neighbors=11, classifier__p=2, classifier__weights=distance;, score=0.688 total time=  11.1s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.000 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=uniform;, score=0.033 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.1min\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.001 total time= 1.0min\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=1, classifier__weights=distance;, score=0.035 total time= 1.0min\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.003 total time=  12.1s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.002 total time=  11.4s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=uniform;, score=0.695 total time=  11.7s\n",
            "[CV 1/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.004 total time=  10.4s\n",
            "[CV 2/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.004 total time=  11.2s\n",
            "[CV 3/3] END classifier__n_neighbors=12, classifier__p=2, classifier__weights=distance;, score=0.696 total time=  11.2s\n",
            "CPU times: user 5h 12min 14s, sys: 1min 11s, total: 5h 13min 25s\n",
            "Wall time: 3h 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_results={}\n",
        "for key in best_knn:\n",
        "  model=best_knn[key]['classifier']\n",
        "  y_pred=model.predict(test_datasets[key])\n",
        "  acc=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "  prec=precision_score(y_true=y_test, y_pred=y_pred)\n",
        "  recall=recall_score(y_true=y_test, y_pred=y_pred)\n",
        "  f1=f1_score(y_true=y_test, y_pred=y_pred)\n",
        "  knn_results[key]=[best_knn[key]['classifier'], acc, prec, recall, f1]"
      ],
      "metadata": {
        "id": "JV37NjYGjD0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_hkrtKpf7cg"
      },
      "outputs": [],
      "source": [
        "df_results=pd.DataFrame.from_dict(knn_results, orient='index')\n",
        "mapping = {df_results.columns[1]: 'Accuracy', df_results.columns[2]: 'Precision', df_results.columns[3]: 'Recall', df_results.columns[4]: 'F1', df_results.columns[0]: 'Tree type'}\n",
        "df_results = df_results.rename(columns=mapping)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nHzwD_tKh2mp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B8eWejhgPVI"
      },
      "source": [
        "## 4.3 Algoritmo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZYspAW1gPjf"
      },
      "outputs": [],
      "source": [
        "estimators = [\n",
        "        ('classifier', SVC(C=1,gamma=\"scale\", kernel=\"rbf\" ))          \n",
        "    ]\n",
        "\n",
        "parameters = {\n",
        "              'classifier__C':[0.1, 1],\n",
        "              'classifier__gamma':['scale', 'auto'],\n",
        "              'classifier__kernel':['linear','rbf'],\n",
        "            }\n",
        "\n",
        "pipe_svm = Pipeline(estimators)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "best_svm={}\n",
        "for key in train_datasets:\n",
        "  grid_search_svm = GridSearchCV(pipe_svm, parameters, scoring='f1', cv=3, verbose=3)\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    grid_search_svm.fit(train_datasets[key],y_train)\n",
        "    best_svm[key]=grid_search_svm.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG8m7qvekkS-",
        "outputId": "e3fd9fd9-50cc-440a-e6ba-977a83865538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.895 total time= 1.3min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.902 total time= 1.3min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.896 total time= 1.3min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.844 total time= 2.9min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.851 total time= 3.0min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.847 total time= 3.1min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.895 total time= 1.5min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.902 total time= 1.5min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.896 total time= 1.5min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.000 total time= 5.3min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.002 total time= 5.1min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.000 total time= 5.2min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.887 total time= 3.6min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.889 total time= 4.3min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.886 total time= 3.4min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.887 total time= 4.6min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.895 total time= 4.2min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.891 total time= 4.2min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=linear;, score=0.887 total time= 2.9min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=linear;, score=0.889 total time= 3.7min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=linear;, score=0.886 total time= 3.1min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.627 total time= 3.8min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.631 total time= 4.2min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.620 total time= 4.1min\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.891 total time= 1.8min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.897 total time= 1.9min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=linear;, score=0.890 total time= 1.8min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.819 total time= 2.8min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.822 total time= 2.7min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.818 total time= 2.8min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.891 total time= 1.8min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.897 total time= 1.9min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=linear;, score=0.890 total time= 1.8min\n",
            "[CV 1/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.289 total time= 4.9min\n",
            "[CV 2/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.308 total time= 4.9min\n",
            "[CV 3/3] END classifier__C=0.1, classifier__gamma=auto, classifier__kernel=rbf;, score=0.291 total time= 4.9min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.880 total time= 4.4min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.886 total time= 4.0min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=linear;, score=0.881 total time= 4.1min\n",
            "[CV 1/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.873 total time= 2.1min\n",
            "[CV 2/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.877 total time= 1.7min\n",
            "[CV 3/3] END classifier__C=1, classifier__gamma=scale, classifier__kernel=rbf;, score=0.877 total time= 1.8min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_results={}\n",
        "for key in best_svm:\n",
        "  model=best_svm[key]['classifier']\n",
        "  y_pred=model.predict(test_datasets[key])\n",
        "  acc=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "  prec=precision_score(y_true=y_test, y_pred=y_pred)\n",
        "  recall=recall_score(y_true=y_test, y_pred=y_pred)\n",
        "  f1=f1_score(y_true=y_test, y_pred=y_pred)\n",
        "  svm_results[key]=[best_svm[key]['classifier'], acc, prec, recall, f1]"
      ],
      "metadata": {
        "id": "Dy1QuMchnoki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results=pd.DataFrame.from_dict(svm_results, orient='index')\n",
        "mapping = {df_results.columns[1]: 'Accuracy', df_results.columns[2]: 'Precision', df_results.columns[3]: 'Recall', df_results.columns[4]: 'F1', df_results.columns[0]: 'Tree type'}\n",
        "df_results = df_results.rename(columns=mapping)\n",
        "df_results"
      ],
      "metadata": {
        "id": "Mi92DY9zntd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSupKq-9gWo0"
      },
      "source": [
        "# V. Seleccion del mejor modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con base en los resultados experimentales es posible determinar que el mejor modelo de todos los evaluados tiene los siguientes parametros :\n",
        "\n",
        "\n",
        "\n",
        "*   Representacio vectorial\n",
        "*   Modelo:SVC\n",
        "*   C:\n",
        "*   Gamma: \n",
        "\n",
        "\n",
        "Se va a hacer una ejecucion de este modelo sobre la totalidad de los datos provistos. Inicialmente se hacen los mismos pasos de preprocesamiento descritos en el numeral 3.2. Dado que estos ya se describieron en detalle aqui se van a ejecutar como un unico bloquellamando las funciones definidas en esa seccion"
      ],
      "metadata": {
        "id": "y_I77qS8Ihjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##notese que aqui se esta utilizando el df completo y no el fragmento 'data small' utilizado para la seleccion del modelo\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "##aca se redefine ytrain y ytest\n",
        "X_train, y_train = train['text'], train['class']\n",
        "X_test, y_test = test['text'], test['class']\n",
        "X_full= X_train.apply(contractions.fix) \n",
        "X_full_test= X_test.apply(contractions.fix) \n",
        "X_full=X_full.apply(to_lowercase)\n",
        "X_full_test=X_full_test.apply(to_lowercase)\n",
        "X_full=X_full.apply(remove_punctuation)\n",
        "X_full_test=X_full_test.apply(remove_punctuation)\n",
        "X_full=X_full.apply(remove_stopwords)\n",
        "X_full_test=X_full_test.apply(remove_stopwords)\n",
        "X_full = X_full.apply(word_tokenize)\n",
        "X_full_test = X_full_test.apply(word_tokenize)\n",
        "X_full = X_full.apply(stem_and_lemmatize) \n",
        "X_full_test = X_full_test.apply(stem_and_lemmatize)\n"
      ],
      "metadata": {
        "id": "EKNaJXHruMqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary = CountVectorizer(binary=True, lowercase = False)\n",
        "X_binary = binary.fit_transform(X_full)\n",
        "print(X_binary.shape)"
      ],
      "metadata": {
        "id": "546H0T4GLkmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_binary_test=binary.transform(X_full_test)\n",
        "print(X_binary_test.shape)"
      ],
      "metadata": {
        "id": "xTMrEW58LmAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##usan parametros del mejor modelo y se ejecuta\n",
        "estimators = [\n",
        "        ('classifier', SVC(C=1,gamma=\"scale\", kernel=\"rbf\" ))          \n",
        "    ]\n",
        "\n",
        "parameters = {\n",
        "              'classifier__C':[0.1, 1],\n",
        "              'classifier__gamma':['scale', 'auto'],\n",
        "              'classifier__kernel':['linear','rbf'],\n",
        "            }\n",
        "pipe_svm = Pipeline(estimators)"
      ],
      "metadata": {
        "id": "_j0WPkBCN9fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_svm = GridSearchCV(pipe_svm, scoring='f1', cv=3, verbose=3)\n",
        "with tf.device('/device:GPU:0'):\n",
        "    grid_search_svm.fit(X_full,y_train)"
      ],
      "metadata": {
        "id": "Y06gSW7HL_bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wloFwIPnhNbr"
      },
      "source": [
        "# VI. Evaluacion de resultados"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}